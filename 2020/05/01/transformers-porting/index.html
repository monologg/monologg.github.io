<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>ë‚´ê°€ ë§Œë“  ELECTRAë¥¼ Huggingface Transformersë¡œ Portingí•˜ê¸° - Monologg Blog</title><meta description="BERT, ALBERT, ELECTRA ë“±ì„ ì§ì ‘ Pretrainí•˜ê²Œ ë˜ë©´ ëª¨ë¸ì´ Tensorflowì˜ ckpt í˜•íƒœë¡œ ì €ì¥ì´ ëœë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” tensorflow ckptë¥¼ transformersì˜ pytorch ckptë¡œ ë³€í™˜í•˜ëŠ” ë²•ì„ ì•Œì•„ë³´ê² ë‹¤ğŸ¤—"><meta property="og:type" content="blog"><meta property="og:title" content="ë‚´ê°€ ë§Œë“  ELECTRAë¥¼ Huggingface Transformersë¡œ Portingí•˜ê¸°"><meta property="og:url" content="https://monologg.kr/2020/05/01/transformers-porting/"><meta property="og:site_name" content="Monologg Blog"><meta property="og:description" content="BERT, ALBERT, ELECTRA ë“±ì„ ì§ì ‘ Pretrainí•˜ê²Œ ë˜ë©´ ëª¨ë¸ì´ Tensorflowì˜ ckpt í˜•íƒœë¡œ ì €ì¥ì´ ëœë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” tensorflow ckptë¥¼ transformersì˜ pytorch ckptë¡œ ë³€í™˜í•˜ëŠ” ë²•ì„ ì•Œì•„ë³´ê² ë‹¤ğŸ¤—"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://monologg.kr/images/2020-05-01-transformers-porting/thumbnail.png"><meta property="article:published_time" content="2020-04-30T15:00:00.000Z"><meta property="article:modified_time" content="2023-08-07T15:40:31.677Z"><meta property="article:author" content="Jangwon Park"><meta property="article:tag" content="nlp"><meta property="article:tag" content="electra"><meta property="article:tag" content="transformers"><meta property="article:tag" content="pytorch"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/images/2020-05-01-transformers-porting/thumbnail.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://monologg.kr/2020/05/01/transformers-porting/"},"headline":"Monologg Blog","image":["https://monologg.kr/images/2020-05-01-transformers-porting/thumbnail.png"],"datePublished":"2020-04-30T15:00:00.000Z","dateModified":"2023-08-07T15:40:31.677Z","author":{"@type":"Person","name":"Jangwon Park"},"description":"BERT, ALBERT, ELECTRA ë“±ì„ ì§ì ‘ Pretrainí•˜ê²Œ ë˜ë©´ ëª¨ë¸ì´ Tensorflowì˜ ckpt í˜•íƒœë¡œ ì €ì¥ì´ ëœë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” tensorflow ckptë¥¼ transformersì˜ pytorch ckptë¡œ ë³€í™˜í•˜ëŠ” ë²•ì„ ì•Œì•„ë³´ê² ë‹¤ğŸ¤—"}</script><link rel="canonical" href="https://monologg.kr/2020/05/01/transformers-porting/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=IBM+Plex+Mono" type="text/css"><link href="//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css" rel="stylesheet" type="text/css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-DECTTCKXQT" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-DECTTCKXQT');</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9379525792094836" crossorigin="anonymous"></script><link rel="alternate" href="/rss2.xml" title="Monologg Blog" type="application/rss+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><i class="fas fa-laptop-code" style="font-size:24px"></i></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/monologg"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="/images/2020-05-01-transformers-porting/thumbnail.png" alt="ë‚´ê°€ ë§Œë“  ELECTRAë¥¼ Huggingface Transformersë¡œ Portingí•˜ê¸°"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" datetime="2020-04-30T15:00:00.000Z" title="2020-04-30T15:00:00.000Z">2020-05-01</time><span class="level-item"><a class="link-muted" href="/categories/NLP/">NLP</a><span>Â /Â </span><a class="link-muted" href="/categories/NLP/Transformers/">Transformers</a></span></div></div><h1 class="title is-3 is-size-4-mobile">ë‚´ê°€ ë§Œë“  ELECTRAë¥¼ Huggingface Transformersë¡œ Portingí•˜ê¸°</h1><div class="content"><p><code>BERT</code>, <code>ALBERT</code>, <code>ELECTRA</code> ë“±ì„ ì§ì ‘ Pretrainí•˜ê²Œ ë˜ë©´ ëª¨ë¸ì´ Tensorflowì˜ ckpt í˜•íƒœë¡œ ì €ì¥ì´ ëœë‹¤.</p>
<p>ì´ë²ˆ ê¸€ì—ì„œëŠ” <code>tensorflow ckpt</code>ë¥¼ transformersì˜ <code>pytorch ckpt</code>ë¡œ ë³€í™˜í•˜ëŠ” ë²•ì„ ì•Œì•„ë³´ê² ë‹¤ğŸ¤—</p>
<a id="more"></a>

<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><ul>
<li>ì´ë²ˆ ê¸€ì—ì„œëŠ” <code>ELECTRA-Small</code>ì„ ê¸°ì¤€ìœ¼ë¡œ ì‹¤ìŠµì„ í•´ë³¸ë‹¤. (<code>BERT</code> ë“±ë„ ë°©ë²•ì€ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šë‹¤)</li>
<li><code>transformers v2.8.0</code>ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ì˜€ë‹¤. ì´í›„ ë²„ì „ì—ì„œ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìˆì„ ìˆ˜ ìˆë‹¤.</li>
<li><code>Transformers</code>ì˜ <code>ELECTRA</code>ëŠ” <code>discriminator</code>ì™€ <code>generator</code>ë¥¼ <strong>ê°ê° ë”°ë¡œ ë§Œë“¤ì–´ì¤˜ì•¼ í•œë‹¤!</strong></li>
</ul>
<h2 id="Prerequisite"><a href="#Prerequisite" class="headerlink" title="Prerequisite"></a>Prerequisite</h2><h3 id="1-Original-Tensorflow-Checkpoint"><a href="#1-Original-Tensorflow-Checkpoint" class="headerlink" title="1. Original Tensorflow Checkpoint"></a>1. Original Tensorflow Checkpoint</h3><p>ë‹¹ì—°íˆ <strong>Tensorflowë¡œ í•™ìŠµí•œ ê²°ê³¼ë¬¼</strong>ì„ ê°€ì§€ê³  ìˆì–´ì•¼ í•œë‹¤.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">â”œâ”€â”€ koelectra-small-tf</span><br><span class="line">â”‚   â”œâ”€â”€ checkpoint</span><br><span class="line">â”‚   â”œâ”€â”€ events.out.tfevents.1586942968.koelectra-small</span><br><span class="line">â”‚   â”œâ”€â”€ graph.pbtxt</span><br><span class="line">â”‚   â”œâ”€â”€ ...</span><br><span class="line">â”‚   â”œâ”€â”€ model.ckpt-700000.data-00000-of-00001</span><br><span class="line">â”‚   â”œâ”€â”€ model.ckpt-700000.index</span><br><span class="line">â”‚   â””â”€â”€ model.ckpt-700000.meta</span><br><span class="line">â””â”€â”€ ...</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><figcaption><span>checkpoint</span></figcaption><table><tr><td class="code"><pre><span class="line">model_checkpoint_path: &quot;model.ckpt-700000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-600000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-625000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-650000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-675000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-700000&quot;</span><br></pre></td></tr></table></figure>

<p>ì£¼ì˜í•  ì ì€ <code>checkpoint</code> íŒŒì¼ì—ì„œ <code>model_checkpoint_path</code> ê°’ì„ <strong>â€œì›í•˜ëŠ” stepì˜ ckptâ€</strong>ë¡œ ë°”ê¿”ì¤˜ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤.</p>
<h3 id="2-config-json"><a href="#2-config-json" class="headerlink" title="2. config.json"></a>2. config.json</h3><blockquote>
<p><strong>(ì£¼ì˜!) <code>transformers</code> ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—…ë°ì´íŠ¸ë˜ë©´ì„œ APIê°€ ë³€ê²½ë˜ëŠ” ê²½ìš°ê°€ ìˆê³ , ì´ì— ë”°ë¼ <code>config.json</code>ì˜ attributeê°€ ì¶”ê°€/ë³€ê²½ë˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤.</strong></p>
</blockquote>
<blockquote>
<p><a href="https://huggingface.co/models" rel="external nofollow noopener noreferrer" target="_blank">https://huggingface.co/models</a>ë¡œ ê°€ì„œ ëŒ€í‘œ ëª¨ë¸ì˜ <code>config.json</code>ì„ ë³´ë©´ì„œ ì§ì ‘ ë§Œë“¤ì–´ì•¼ í•œë‹¤.</p>
</blockquote>
<ul>
<li><code>vocab_size</code> ë³€ê²½ì—ë§Œ ì£¼ì˜í•˜ë©´ ì¶©ë¶„í•¨</li>
<li>ë§Œì¼ <code>max_seq_length</code>ë¥¼ ë°”ê¿¨ë‹¤ë©´ <code>max_position_embeddings</code>ë„ ë°”ê¿”ì•¼ í•¨</li>
</ul>
<figure class="highlight json"><figcaption><span>discriminator</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"architectures"</span>: [<span class="string">"ElectraForPreTraining"</span>],</span><br><span class="line">  <span class="attr">"attention_probs_dropout_prob"</span>: <span class="number">0.1</span>,</span><br><span class="line">  <span class="attr">"embedding_size"</span>: <span class="number">128</span>,</span><br><span class="line">  <span class="attr">"hidden_act"</span>: <span class="string">"gelu"</span>,</span><br><span class="line">  <span class="attr">"hidden_dropout_prob"</span>: <span class="number">0.1</span>,</span><br><span class="line">  <span class="attr">"hidden_size"</span>: <span class="number">256</span>,</span><br><span class="line">  <span class="attr">"initializer_range"</span>: <span class="number">0.02</span>,</span><br><span class="line">  <span class="attr">"intermediate_size"</span>: <span class="number">1024</span>,</span><br><span class="line">  <span class="attr">"layer_norm_eps"</span>: <span class="number">1e-12</span>,</span><br><span class="line">  <span class="attr">"max_position_embeddings"</span>: <span class="number">512</span>,</span><br><span class="line">  <span class="attr">"model_type"</span>: <span class="string">"electra"</span>,</span><br><span class="line">  <span class="attr">"num_attention_heads"</span>: <span class="number">4</span>,</span><br><span class="line">  <span class="attr">"num_hidden_layers"</span>: <span class="number">12</span>,</span><br><span class="line">  <span class="attr">"pad_token_id"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"type_vocab_size"</span>: <span class="number">2</span>,</span><br><span class="line">  <span class="attr">"vocab_size"</span>: <span class="number">32200</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><figcaption><span>generator</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"architectures"</span>: [<span class="string">"ElectraForMaskedLM"</span>],</span><br><span class="line">  <span class="attr">"attention_probs_dropout_prob"</span>: <span class="number">0.1</span>,</span><br><span class="line">  <span class="attr">"embedding_size"</span>: <span class="number">128</span>,</span><br><span class="line">  <span class="attr">"hidden_act"</span>: <span class="string">"gelu"</span>,</span><br><span class="line">  <span class="attr">"hidden_dropout_prob"</span>: <span class="number">0.1</span>,</span><br><span class="line">  <span class="attr">"hidden_size"</span>: <span class="number">256</span>,</span><br><span class="line">  <span class="attr">"initializer_range"</span>: <span class="number">0.02</span>,</span><br><span class="line">  <span class="attr">"intermediate_size"</span>: <span class="number">1024</span>,</span><br><span class="line">  <span class="attr">"layer_norm_eps"</span>: <span class="number">1e-12</span>,</span><br><span class="line">  <span class="attr">"max_position_embeddings"</span>: <span class="number">512</span>,</span><br><span class="line">  <span class="attr">"model_type"</span>: <span class="string">"electra"</span>,</span><br><span class="line">  <span class="attr">"num_attention_heads"</span>: <span class="number">4</span>,</span><br><span class="line">  <span class="attr">"num_hidden_layers"</span>: <span class="number">12</span>,</span><br><span class="line">  <span class="attr">"pad_token_id"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"type_vocab_size"</span>: <span class="number">2</span>,</span><br><span class="line">  <span class="attr">"vocab_size"</span>: <span class="number">32200</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-tokenizer-config-json"><a href="#3-tokenizer-config-json" class="headerlink" title="3. tokenizer_config.json"></a>3. tokenizer_config.json</h3><p><code>cased</code> ëª¨ë¸ì˜ ê²½ìš° ê·¸ëƒ¥ tokenizerë¥¼ loadí•˜ë©´ ë§¤ë²ˆ <code>do_lower_case=False</code>ë¥¼ ì§ì ‘ ì¶”ê°€í•´ì¤˜ì•¼ í•œë‹¤.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> ElectraTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = ElectraTokenizer.from_pretrained(<span class="string">"monologg/koelectra-small-discriminator"</span>,</span><br><span class="line">                                             do_lower_case=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><code>tokenizer_config.json</code>ì„ ë§Œë“¤ì–´ì£¼ë©´ ì´ëŸ¬í•œ ë²ˆê±°ë¡œì›€ì„ ì—†ì•¨ ìˆ˜ ìˆë‹¤.<br>(ë§Œì¼ <code>max_seq_length</code>ê°€ 128ì´ë©´ <code>model_max_length</code>ë„ 128ë¡œ ë°”ê¿”ì£¼ë©´ ëœë‹¤.)</p>
<figure class="highlight json"><figcaption><span>tokenizer_config.json</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"do_lower_case"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"model_max_length"</span>: <span class="number">512</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-vocab-txt"><a href="#4-vocab-txt" class="headerlink" title="4. vocab.txt"></a>4. vocab.txt</h3><p>tensorflowì—ì„œ í•™ìŠµí–ˆì„ ë•Œ ì“´ <code>vocab.txt</code>ë¥¼ ê·¸ëŒ€ë¡œ ì“°ë©´ ëœë‹¤.</p>
<h3 id="5-ìµœì¢…ì ì¸-ë””ë ‰í† ë¦¬-í˜•íƒœ"><a href="#5-ìµœì¢…ì ì¸-ë””ë ‰í† ë¦¬-í˜•íƒœ" class="headerlink" title="5. ìµœì¢…ì ì¸ ë””ë ‰í† ë¦¬ í˜•íƒœ"></a>5. ìµœì¢…ì ì¸ ë””ë ‰í† ë¦¬ í˜•íƒœ</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">â”œâ”€â”€ koelectra-small-tf</span><br><span class="line">â”‚   â”œâ”€â”€ checkpoint</span><br><span class="line">â”‚   â”œâ”€â”€ events.out.tfevents.1586942968.koelectra-small</span><br><span class="line">â”‚   â”œâ”€â”€ graph.pbtxt</span><br><span class="line">â”‚   â”œâ”€â”€ ...</span><br><span class="line">â”‚   â”œâ”€â”€ model.ckpt-700000.data-00000-of-00001</span><br><span class="line">â”‚   â”œâ”€â”€ model.ckpt-700000.index</span><br><span class="line">â”‚   â””â”€â”€ model.ckpt-700000.meta</span><br><span class="line">â”‚</span><br><span class="line">â”œâ”€â”€ electra-small-discriminator</span><br><span class="line">â”‚   â”œâ”€â”€ config.json</span><br><span class="line">â”‚   â”œâ”€â”€ tokenizer_config.json</span><br><span class="line">â”‚   â””â”€â”€ vocab.txt</span><br><span class="line">â”‚</span><br><span class="line">â”œâ”€â”€ electra-small-generator</span><br><span class="line">â”‚   â”œâ”€â”€ config.json</span><br><span class="line">â”‚   â”œâ”€â”€ tokenizer_config.json</span><br><span class="line">â”‚   â””â”€â”€ vocab.txt</span><br><span class="line">â””â”€â”€ ...</span><br></pre></td></tr></table></figure>

<ul>
<li><code>electra-small-discriminator</code>ì™€ <code>electra-small-generator</code> í´ë”ë¥¼ ê°ê° ë§Œë“ ë‹¤.</li>
<li><code>config.json</code>ì€ discriminatorìš©ê³¼ generatorìš©ì„ <strong>ë”°ë¡œ</strong> ë§Œë“¤ì–´ì„œ í´ë” ì•ˆì— ë„£ëŠ”ë‹¤.</li>
<li><code>tokenizer_config.json</code>ê³¼ <code>vocab.txt</code>ëŠ” discriminatorì™€ generator ë‘˜ ë‹¤ <strong>ë™ì¼í•œ íŒŒì¼</strong>ì„ ë„£ìœ¼ë©´ ëœë‹¤.</li>
</ul>
<h2 id="Convert"><a href="#Convert" class="headerlink" title="Convert"></a>Convert</h2><figure class="highlight python"><figcaption><span>convert.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> transformers.convert_electra_original_tf_checkpoint_to_pytorch <span class="keyword">import</span> convert_tf_checkpoint_to_pytorch</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line"></span><br><span class="line">parser.add_argument(<span class="string">"--tf_ckpt_path"</span>, type=str, default=<span class="string">"koelectra-small-tf"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--pt_discriminator_path"</span>, type=str, default=<span class="string">"koelectra-small-discriminator"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--pt_generator_path"</span>, type=str, default=<span class="string">"koelectra-small-generator"</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">convert_tf_checkpoint_to_pytorch(tf_checkpoint_path=args.tf_ckpt_path,</span><br><span class="line">                                 config_file=os.path.join(args.pt_discriminator_path, <span class="string">"config.json"</span>),</span><br><span class="line">                                 pytorch_dump_path=os.path.join(args.pt_discriminator_path, <span class="string">"pytorch_model.bin"</span>),</span><br><span class="line">                                 discriminator_or_generator=<span class="string">"discriminator"</span>)</span><br><span class="line"></span><br><span class="line">convert_tf_checkpoint_to_pytorch(tf_checkpoint_path=args.tf_ckpt_path,</span><br><span class="line">                                 config_file=os.path.join(args.pt_generator_path, <span class="string">"config.json"</span>),</span><br><span class="line">                                 pytorch_dump_path=os.path.join(args.pt_generator_path, <span class="string">"pytorch_model.bin"</span>),</span><br><span class="line">                                 discriminator_or_generator=<span class="string">"generator"</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Upload-your-model-to-Huggingface-s3"><a href="#Upload-your-model-to-Huggingface-s3" class="headerlink" title="Upload your model to Huggingface s3"></a>Upload your model to Huggingface s3</h2><ol>
<li>ë¨¼ì € <a href="https://huggingface.co/" rel="external nofollow noopener noreferrer" target="_blank">huggingface.co</a>ë¡œ ê°€ì„œ <strong>íšŒì›ê°€ì…</strong>ì„ í•´ì•¼ í•¨</li>
<li>ì•„ë˜ì˜ ëª…ë ¹ì–´ë¡œ s3ì— ì—…ë¡œë“œ ì§„í–‰</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ transformers-cli login</span><br><span class="line">$ transformers-cli upload koelectra-small-discriminator</span><br><span class="line">$ transformers-cli upload koelectra-small-generator</span><br></pre></td></tr></table></figure>

<h2 id="Now-Letâ€™s-Use-It"><a href="#Now-Letâ€™s-Use-It" class="headerlink" title="Now Letâ€™s Use It"></a>Now Letâ€™s Use It</h2><figure class="highlight python"><figcaption><span>How to Use</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> ElectraModel, ElectraTokenizer</span><br><span class="line"></span><br><span class="line">model = ElectraModel.from_pretrained(<span class="string">"monologg/koelectra-small-discriminator"</span>)</span><br><span class="line">tokenizer = ElectraTokenizer.from_pretrained(<span class="string">"monologg/koelectra-small-discriminator"</span>)</span><br></pre></td></tr></table></figure>

<h2 id="ë§ºìœ¼ë©°"><a href="#ë§ºìœ¼ë©°" class="headerlink" title="ë§ºìœ¼ë©°"></a>ë§ºìœ¼ë©°</h2><center>

<p><img src="/images/2020-05-01-transformers-porting/model_download.png" alt="ìƒê°ë³´ë‹¤ ë§ì´ ì‚¬ìš©í•˜ì‹œë„¤..."></p>
</center>

<p>ì‚¬ì‹¤ Model Portingê³¼ ê´€ë ¨í•˜ì—¬ <strong>ëª…í™•í•œ Documentationì´ ì—†ì–´</strong> ë‚˜ë„ ì‚½ì§ˆì„ ìƒë‹¹íˆ í–ˆë˜ ë¶€ë¶„ì´ë‹¤. ì´ë²ˆ ë‚´ìš©ì´ ë‹¤ë¥¸ ë¶„ë“¤ì—ê²Œ ë„ì›€ì´ ë˜ì—ˆìœ¼ë©´ í•œë‹¤ğŸ˜›</p>
<p>ë˜í•œ <strong>Huggingface s3ì— ëª¨ë¸ì„ ì—…ë¡œë“œ</strong>í•˜ëŠ” ê²ƒì€ ê¼­ ì‚¬ìš©í•´ë³´ê¸¸ ê¶Œí•œë‹¤. ì´ ê¸°ëŠ¥ì´ ìƒê¸´ì§€ ì–¼ë§ˆë˜ì§€ ì•Šì•„ì„œ ëª¨ë¥´ì‹œëŠ” ë¶„ë“¤ì´ ìˆëŠ”ë°, <strong>ì—…ë¡œë“œ ìš©ëŸ‰ì˜ ì œí•œë„ ì—†ê³ </strong> ì—¬ëŸ¬ëª¨ë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ë„ í¸í•´ì§„ë‹¤. (ëª¨ë¸ì„ 100ê°œ ì´ìƒ ì˜¬ë¦°ë‹¤ê³  Huggingface íŒ€ì—ì„œ ë­ë¼ê³  í•˜ì§€ ì•Šìœ¼ë‹ˆ ë§ì´ë“¤ ì“°ì…¨ìœ¼ë©´ã…ã…)</p>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/nlp/">nlp</a><a class="link-muted mr-2" rel="tag" href="/tags/electra/">electra</a><a class="link-muted mr-2" rel="tag" href="/tags/transformers/">transformers</a><a class="link-muted mr-2" rel="tag" href="/tags/pytorch/">pytorch</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5ea69e998fb91e001b32120c&amp;product=inline-share-buttons" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/05/02/koelectra-part1/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">2ì£¼ ê°„ì˜ KoELECTRA ê°œë°œê¸° - 1ë¶€</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/04/27/wordpiece-vocab/"><span class="level-item">ë‚˜ë§Œì˜ BERT Wordpiece Vocab ë§Œë“¤ê¸°</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3 is-sticky"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#Intro"><span class="mr-2">1</span><span>Intro</span></a></li><li><a class="is-flex" href="#Prerequisite"><span class="mr-2">2</span><span>Prerequisite</span></a><ul class="menu-list"><li><a class="is-flex" href="#1-Original-Tensorflow-Checkpoint"><span class="mr-2">2.1</span><span>1. Original Tensorflow Checkpoint</span></a></li><li><a class="is-flex" href="#2-config-json"><span class="mr-2">2.2</span><span>2. config.json</span></a></li><li><a class="is-flex" href="#3-tokenizer-config-json"><span class="mr-2">2.3</span><span>3. tokenizer_config.json</span></a></li><li><a class="is-flex" href="#4-vocab-txt"><span class="mr-2">2.4</span><span>4. vocab.txt</span></a></li><li><a class="is-flex" href="#5-ìµœì¢…ì ì¸-ë””ë ‰í† ë¦¬-í˜•íƒœ"><span class="mr-2">2.5</span><span>5. ìµœì¢…ì ì¸ ë””ë ‰í† ë¦¬ í˜•íƒœ</span></a></li></ul></li><li><a class="is-flex" href="#Convert"><span class="mr-2">3</span><span>Convert</span></a></li><li><a class="is-flex" href="#Upload-your-model-to-Huggingface-s3"><span class="mr-2">4</span><span>Upload your model to Huggingface s3</span></a></li><li><a class="is-flex" href="#Now-Letâ€™s-Use-It"><span class="mr-2">5</span><span>Now Letâ€™s Use It</span></a></li><li><a class="is-flex" href="#ë§ºìœ¼ë©°"><span class="mr-2">6</span><span>ë§ºìœ¼ë©°</span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><a class="media-left" href="/2020/05/02/koelectra-part2/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-05-02-koelectra-part2/thumbnail.jpg" alt="2ì£¼ ê°„ì˜ KoELECTRA ê°œë°œê¸° - 2ë¶€"></p></a><div class="media-content size-small"><p><time datetime="2020-05-01T18:00:00.000Z">2020-05-02</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/02/koelectra-part2/">2ì£¼ ê°„ì˜ KoELECTRA ê°œë°œê¸° - 2ë¶€</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/ELECTRA/">ELECTRA</a></p></div></article><article class="media"><a class="media-left" href="/2020/05/02/koelectra-part1/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-05-02-koelectra-part1/thumbnail.png" alt="2ì£¼ ê°„ì˜ KoELECTRA ê°œë°œê¸° - 1ë¶€"></p></a><div class="media-content size-small"><p><time datetime="2020-05-01T16:00:00.000Z">2020-05-02</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/02/koelectra-part1/">2ì£¼ ê°„ì˜ KoELECTRA ê°œë°œê¸° - 1ë¶€</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/ELECTRA/">ELECTRA</a></p></div></article><article class="media"><a class="media-left" href="/2020/05/01/transformers-porting/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-05-01-transformers-porting/thumbnail.png" alt="ë‚´ê°€ ë§Œë“  ELECTRAë¥¼ Huggingface Transformersë¡œ Portingí•˜ê¸°"></p></a><div class="media-content size-small"><p><time datetime="2020-04-30T15:00:00.000Z">2020-05-01</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/01/transformers-porting/">ë‚´ê°€ ë§Œë“  ELECTRAë¥¼ Huggingface Transformersë¡œ Portingí•˜ê¸°</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/Transformers/">Transformers</a></p></div></article><article class="media"><a class="media-left" href="/2020/04/27/wordpiece-vocab/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-04-28-wordpiece-vocab/thumbnail.jpg" alt="ë‚˜ë§Œì˜ BERT Wordpiece Vocab ë§Œë“¤ê¸°"></p></a><div class="media-content size-small"><p><time datetime="2020-04-26T15:00:00.000Z">2020-04-27</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/27/wordpiece-vocab/">ë‚˜ë§Œì˜ BERT Wordpiece Vocab ë§Œë“¤ê¸°</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/Wordpiece/">Wordpiece</a></p></div></article><article class="media"><a class="media-left" href="/2020/04/20/tpu-electra/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-04-20-tpu-electra/thumbnail.jpg" alt="TPUë¥¼ ì´ìš©í•˜ì—¬ Electra Pretrainingí•˜ê¸°"></p></a><div class="media-content size-small"><p><time datetime="2020-04-19T15:00:00.000Z">2020-04-20</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/20/tpu-electra/">TPUë¥¼ ì´ìš©í•˜ì—¬ Electra Pretrainingí•˜ê¸°</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/TPU/">TPU</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><i class="fas fa-laptop-code" style="font-size:24px"></i></a><p class="size-small"><span>&copy; 2023 Jangwon Park</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://monologg.kr',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: ''
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript">var infolinks_pid = 3364207; var infolinks_wsid = 0;</script><script type="text/javascript" src="http://resources.infolinks.com/js/infolinks_main.js"></script></body></html>