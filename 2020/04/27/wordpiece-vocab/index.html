<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>나만의 BERT Wordpiece Vocab 만들기 - Monologg Blog</title><meta description="개인적으로 Pretrained Language Model 성능에 큰 영향을 주는 것 중 하나로 Vocab quality라고 생각한다. 이번 포스트에서는 tokenization의 방법 중 하나인 Wordpiece를 이용하여 어떻게 vocab을 만드는지 알아보려 한다:)"><meta property="og:type" content="blog"><meta property="og:title" content="나만의 BERT Wordpiece Vocab 만들기"><meta property="og:url" content="https://monologg.kr/2020/04/27/wordpiece-vocab/"><meta property="og:site_name" content="Monologg Blog"><meta property="og:description" content="개인적으로 Pretrained Language Model 성능에 큰 영향을 주는 것 중 하나로 Vocab quality라고 생각한다. 이번 포스트에서는 tokenization의 방법 중 하나인 Wordpiece를 이용하여 어떻게 vocab을 만드는지 알아보려 한다:)"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://monologg.kr/images/2020-04-28-wordpiece-vocab/thumbnail.jpg"><meta property="article:published_time" content="2020-04-26T15:00:00.000Z"><meta property="article:modified_time" content="2023-08-07T15:40:31.677Z"><meta property="article:author" content="Jangwon Park"><meta property="article:tag" content="nlp"><meta property="article:tag" content="wordpiece"><meta property="article:tag" content="tokenization"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/images/2020-04-28-wordpiece-vocab/thumbnail.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://monologg.kr/2020/04/27/wordpiece-vocab/"},"headline":"Monologg Blog","image":["https://monologg.kr/images/2020-04-28-wordpiece-vocab/thumbnail.jpg"],"datePublished":"2020-04-26T15:00:00.000Z","dateModified":"2023-08-07T15:40:31.677Z","author":{"@type":"Person","name":"Jangwon Park"},"description":"개인적으로 Pretrained Language Model 성능에 큰 영향을 주는 것 중 하나로 Vocab quality라고 생각한다. 이번 포스트에서는 tokenization의 방법 중 하나인 Wordpiece를 이용하여 어떻게 vocab을 만드는지 알아보려 한다:)"}</script><link rel="canonical" href="https://monologg.kr/2020/04/27/wordpiece-vocab/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=IBM+Plex+Mono" type="text/css"><link href="//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css" rel="stylesheet" type="text/css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-DECTTCKXQT" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-DECTTCKXQT');</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9379525792094836" crossorigin="anonymous"></script><link rel="alternate" href="/rss2.xml" title="Monologg Blog" type="application/rss+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><i class="fas fa-laptop-code" style="font-size:24px"></i></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/monologg"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="/images/2020-04-28-wordpiece-vocab/thumbnail.jpg" alt="나만의 BERT Wordpiece Vocab 만들기"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" datetime="2020-04-26T15:00:00.000Z" title="2020-04-26T15:00:00.000Z">2020-04-27</time><span class="level-item"><a class="link-muted" href="/categories/NLP/">NLP</a><span> / </span><a class="link-muted" href="/categories/NLP/Wordpiece/">Wordpiece</a></span></div></div><h1 class="title is-3 is-size-4-mobile">나만의 BERT Wordpiece Vocab 만들기</h1><div class="content"><p>개인적으로 Pretrained Language Model 성능에 큰 영향을 주는 것 중 하나로 <code>Vocab quality</code>라고 생각한다.</p>
<p>이번 포스트에서는 tokenization의 방법 중 하나인 <code>Wordpiece</code>를 이용하여 어떻게 vocab을 만드는지 알아보려 한다:)</p>
<a id="more"></a>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>한국어 Tokenizer의 대안으로는 크게 <code>Sentencepiece</code>, <code>Mecab</code>, <code>Wordpiece</code>가 있다. (<em>여기서의 wordpiece는 Google의 BERT에서 사용된 wordpiece로 가정한다.</em>)</p>
<p>BERT, ELECTRA 등은 기본적으로 <code>Wordpiece</code>를 사용하기에 공식 코드에서 기본적으로 제공되는 Tokenizer 역시 이에 호환되게 코드가 작성되었다. 즉, <code>Sentencepiece</code>나 <code>Mecab</code>을 사용하려면 <strong>별도의 Tokenizer</strong>를 직접 만들어야 하고, 이렇게 되면 <code>transformers</code> 등의 라이브러리에서 모델을 곧바로 사용하는데 불편함이 생기게 된다.</p>
<h2 id="Original-wordpiece-code-is-NOT-available"><a href="#Original-wordpiece-code-is-NOT-available" class="headerlink" title="Original wordpiece code is NOT available!"></a>Original wordpiece code is NOT available!</h2><p float="left" align="left">
    <img width="800" src="https://user-images.githubusercontent.com/28896432/80015023-19f7e680-850c-11ea-90d3-436ca253a7a1.png">  
</p>

<p><strong>공식 BERT에서 사용된 Wordpiece Builder는 제공되지 않고 있다</strong>. BERT 공식 Github에서 다른 대안들을 제시해줬지만, 완전히 동일한 Wordpiece Vocab이 나오지 않았다.</p>
<p>몇몇 오픈소스들이 Wordpiece vocab builder를 구현하였지만 <strong>input file이 매우 클 시 메모리, 속도 등의 이슈</strong>가 종종 발생한다ㅠ</p>
<h2 id="Huggingface-Tokenizers"><a href="#Huggingface-Tokenizers" class="headerlink" title="Huggingface Tokenizers"></a>Huggingface Tokenizers</h2><p float="left" align="center">
    <img width="600" src="https://user-images.githubusercontent.com/28896432/80016455-1c5b4000-850e-11ea-8432-3c356c11f932.png">  
</p>

<p>최종적으로, 최근 Huggingface에서 발표한 <code>Tokenizers</code> 라이브러리를 이용하여 Wordpiece Vocabulary를 만드는게 제일 좋았다.</p>
<p>해당 라이브러리를 사용하면 Corpus가 매우 커도 메모리 이슈가 발생하지 않으며, <code>Rust</code>로 구현이 되어있어 속도 또한 Python보다 빠르다😃</p>
<h2 id="Code-for-building-Wordpiece-vocab"><a href="#Code-for-building-Wordpiece-vocab" class="headerlink" title="Code for building Wordpiece vocab"></a>Code for building Wordpiece vocab</h2><p><strong>(tokenizer v0.7.0 기준으로 작성하였다. 현재도 라이브러리가 업데이트 중이어서 api가 달라질 수도…)</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> tokenizers <span class="keyword">import</span> BertWordPieceTokenizer</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line"></span><br><span class="line">parser.add_argument(<span class="string">"--corpus_file"</span>, type=str)</span><br><span class="line">parser.add_argument(<span class="string">"--vocab_size"</span>, type=int, default=<span class="number">32000</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--limit_alphabet"</span>, type=int, default=<span class="number">6000</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">tokenizer = BertWordPieceTokenizer(</span><br><span class="line">    vocab_file=<span class="literal">None</span>,</span><br><span class="line">    clean_text=<span class="literal">True</span>,</span><br><span class="line">    handle_chinese_chars=<span class="literal">True</span>,</span><br><span class="line">    strip_accents=<span class="literal">False</span>, <span class="comment"># Must be False if cased model</span></span><br><span class="line">    lowercase=<span class="literal">False</span>,</span><br><span class="line">    wordpieces_prefix=<span class="string">"##"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tokenizer.train(</span><br><span class="line">    files=[args.corpus_file],</span><br><span class="line">    limit_alphabet=args.limit_alphabet,</span><br><span class="line">    vocab_size=args.vocab_size</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tokenizer.save(<span class="string">"./"</span>, <span class="string">"ch-&#123;&#125;-wpm-&#123;&#125;"</span>.format(args.limit_alphabet, args.vocab_size))</span><br></pre></td></tr></table></figure>

<ul>
<li><p>주의해야할 점은 <code>lowercase=False</code>로 할 시 <code>strip_accent=False</code>로 해줘야 한다는 것!</p>
</li>
<li><p><code>[UNK]</code>의 비중을 최대한 줄이기 위해 <strong>모든 character를 커버</strong>할 수 있도록 처리하였다. (<code>limit_alphabet</code>)</p>
</li>
<li><p>Corpus의 전처리가 완료되었다는 전제하에 sentencepiece와 비교했을 때 <strong>UNK Ratio가 훨씬 낮았다.</strong></p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://wikidocs.net/22592" rel="external nofollow noopener noreferrer" target="_blank">Sentencepiece vs Wordpiece</a></li>
<li><a href="https://github.com/google-research/bert#learning-a-new-wordpiece-vocabulary" rel="external nofollow noopener noreferrer" target="_blank">Learning a new WordPiece vocabulary</a></li>
<li><a href="https://github.com/kwonmha/bert-vocab-builder" rel="external nofollow noopener noreferrer" target="_blank">kwonmha’s bert-vocab-builder</a></li>
<li><a href="https://github.com/huggingface/tokenizers" rel="external nofollow noopener noreferrer" target="_blank">Huggingface Tokenizers</a></li>
</ul>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/nlp/">nlp</a><a class="link-muted mr-2" rel="tag" href="/tags/wordpiece/">wordpiece</a><a class="link-muted mr-2" rel="tag" href="/tags/tokenization/">tokenization</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5ea69e998fb91e001b32120c&amp;product=inline-share-buttons" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/05/01/transformers-porting/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">내가 만든 ELECTRA를 Huggingface Transformers로 Porting하기</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/04/20/tpu-electra/"><span class="level-item">TPU를 이용하여 Electra Pretraining하기</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3 is-sticky"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#Introduction"><span class="mr-2">1</span><span>Introduction</span></a></li><li><a class="is-flex" href="#Original-wordpiece-code-is-NOT-available"><span class="mr-2">2</span><span>Original wordpiece code is NOT available!</span></a></li><li><a class="is-flex" href="#Huggingface-Tokenizers"><span class="mr-2">3</span><span>Huggingface Tokenizers</span></a></li><li><a class="is-flex" href="#Code-for-building-Wordpiece-vocab"><span class="mr-2">4</span><span>Code for building Wordpiece vocab</span></a></li><li><a class="is-flex" href="#Reference"><span class="mr-2">5</span><span>Reference</span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><a class="media-left" href="/2020/05/02/koelectra-part2/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-05-02-koelectra-part2/thumbnail.jpg" alt="2주 간의 KoELECTRA 개발기 - 2부"></p></a><div class="media-content size-small"><p><time datetime="2020-05-01T18:00:00.000Z">2020-05-02</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/02/koelectra-part2/">2주 간의 KoELECTRA 개발기 - 2부</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/ELECTRA/">ELECTRA</a></p></div></article><article class="media"><a class="media-left" href="/2020/05/02/koelectra-part1/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-05-02-koelectra-part1/thumbnail.png" alt="2주 간의 KoELECTRA 개발기 - 1부"></p></a><div class="media-content size-small"><p><time datetime="2020-05-01T16:00:00.000Z">2020-05-02</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/02/koelectra-part1/">2주 간의 KoELECTRA 개발기 - 1부</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/ELECTRA/">ELECTRA</a></p></div></article><article class="media"><a class="media-left" href="/2020/05/01/transformers-porting/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-05-01-transformers-porting/thumbnail.png" alt="내가 만든 ELECTRA를 Huggingface Transformers로 Porting하기"></p></a><div class="media-content size-small"><p><time datetime="2020-04-30T15:00:00.000Z">2020-05-01</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/01/transformers-porting/">내가 만든 ELECTRA를 Huggingface Transformers로 Porting하기</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/Transformers/">Transformers</a></p></div></article><article class="media"><a class="media-left" href="/2020/04/27/wordpiece-vocab/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-04-28-wordpiece-vocab/thumbnail.jpg" alt="나만의 BERT Wordpiece Vocab 만들기"></p></a><div class="media-content size-small"><p><time datetime="2020-04-26T15:00:00.000Z">2020-04-27</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/27/wordpiece-vocab/">나만의 BERT Wordpiece Vocab 만들기</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/Wordpiece/">Wordpiece</a></p></div></article><article class="media"><a class="media-left" href="/2020/04/20/tpu-electra/"><p class="image is-64x64"><img class="thumbnail" src="/images/2020-04-20-tpu-electra/thumbnail.jpg" alt="TPU를 이용하여 Electra Pretraining하기"></p></a><div class="media-content size-small"><p><time datetime="2020-04-19T15:00:00.000Z">2020-04-20</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/20/tpu-electra/">TPU를 이용하여 Electra Pretraining하기</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/NLP/">NLP</a> / <a class="link-muted" href="/categories/NLP/TPU/">TPU</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><i class="fas fa-laptop-code" style="font-size:24px"></i></a><p class="size-small"><span>&copy; 2023 Jangwon Park</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://monologg.kr',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: ''
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript">var infolinks_pid = 3364207; var infolinks_wsid = 0;</script><script type="text/javascript" src="http://resources.infolinks.com/js/infolinks_main.js"></script></body></html>